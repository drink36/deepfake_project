import torch
import torch.nn as nn
import lightning.pytorch as pl
from transformers import AutoModel, AutoConfig

class DeepfakeVideoMAEV2(pl.LightningModule):
    def __init__(self, learning_rate=1e-4, num_classes=1, freeze_backbone=False, distributed=False):
        super().__init__()
        self.save_hyperparameters()
        self.distributed = distributed
        model_name = "OpenGVLab/VideoMAEv2-Base" 
        print(f"ðŸš€ Loading {model_name} (Backbone Only)...")
        
        # 1. è¼‰å…¥ Config (ç‚ºäº†æ‹¿ hidden_size)
        config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)
        

        self.backbone = AutoModel.from_pretrained(
            model_name,
            trust_remote_code=True,
            config=config
        )
        hidden_dim = config.model_config['embed_dim'] if isinstance(config.model_config, dict) else config.model_config.embed_dim
        # 3. æ‰‹å‹•å»ºç«‹åˆ†é¡žé ­ (Head)
        # VideoMAE V2 Base çš„ hidden_size é€šå¸¸æ˜¯ 768
        self.classifier = nn.Linear(hidden_dim, num_classes)
        
        # === å‡çµé‚è¼¯ (Partial Fine-tuning) ===
        if freeze_backbone:
            print("â„ï¸  Freezing Backbone... Only training the Classifier!")
            for param in self.backbone.parameters():
                param.requires_grad = False
            for param in self.classifier.parameters():
                param.requires_grad = True
        else:
            # å»ºè­°è‡³å°‘å‡çµ Patch Embedding (é€™åœ¨å°æ•¸æ“šé›†ä¸Šå¾ˆæœ‰æ•ˆ)
            print("ðŸ”§ Full Fine-tuning (with frozen patch_embed)")
            for name, param in self.backbone.named_parameters():
                 if 'patch_embed' in name:
                     param.requires_grad = False

    def forward(self, x):
        # 1. ç¶­åº¦ä¿®æ­£ (Input Shape Fix)
        # ç¢ºä¿è¼¸å…¥æ˜¯ (B, C, T, H, W)
        if x.shape[1] != 3 and x.shape[2] == 3:
             x = x.permute(0, 2, 1, 3, 4)
        
        # 2. é€šéŽ Backbone
        outputs = self.backbone(x)
        
        # 3. è¼¸å‡ºè™•ç† (Output Handling)
        if isinstance(outputs, torch.Tensor):
            features = outputs
        elif hasattr(outputs, 'last_hidden_state'):
            features = outputs.last_hidden_state
        else:
            features = outputs[0]
            
        # === 4. æ™ºæ…§æ± åŒ– (Smart Pooling) [é—œéµä¿®æ­£] ===
        # æª¢æŸ¥ç¶­åº¦ï¼š
        # å¦‚æžœæ˜¯ (Batch, Seq, Hidden) -> éœ€è¦ Pooling
        # å¦‚æžœæ˜¯ (Batch, Hidden)      -> å·²ç¶“ Pool éŽäº†ï¼Œç›´æŽ¥ç”¨
        
        if features.dim() == 3:
            pooled_features = features.mean(dim=1)
        elif features.dim() == 2:
            pooled_features = features
        else:
            raise ValueError(f"Unexpected features shape: {features.shape}, expected 2D or 3D tensor.")
        
        # 5. é€šéŽåˆ†é¡žé ­
        logits = self.classifier(pooled_features)
        
        return logits

    def training_step(self, batch, batch_idx):
        x, y = batch[:2]
        logits = self(x)
        loss = nn.BCEWithLogitsLoss()(logits.squeeze(), y.float())
        self.log('train_loss', loss, prog_bar=True)
        return loss

    def validation_step(self, batch, batch_idx):
        x, y = batch[:2]
        logits = self(x)
        loss = nn.BCEWithLogitsLoss()(logits.squeeze(), y.float())
        preds = torch.sigmoid(logits.squeeze()) > 0.5
        acc = (preds == y).float().mean()
        self.log('val_loss', loss, prog_bar=True)
        self.log('val_acc', acc, prog_bar=True)
        return loss

    def configure_optimizers(self):
        return torch.optim.AdamW(
            filter(lambda p: p.requires_grad, self.parameters()), 
            lr=self.hparams.learning_rate, 
            weight_decay=0.05
        )